<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title type="text">
        Lucas DiCioccio's blog
    </title>
    <id>
        https://dicioccio.fr/atom.xml
    </id>
    <updated>
        2022-01-30T12:00:00Z
    </updated>
    <entry>
        <id>
            https://dicioccio.fr/on-dualities.html
        </id>
        <title type="text">
            On Dualities
        </title>
        <updated>
            2022-03-27T01:00:00Z
        </updated>
        <author>
            <name>
                Lucas DiCioccio
            </name>
        </author>
        <content type="html">
            &lt;div class="main-article"&gt;&lt;section class="main-section"&gt;&lt;p&gt;Functional programming has taught me to &lt;em&gt;simplify&lt;/em&gt; superfluous concepts: identify what are primitive concepts and what are constructions on top these primitives. The constructions themselves need not be multiplied out of proportion: it is better to stick to few ways of combining entities and concepts. Overall, I think I found some internal peace with programming languages when I could recognize enough of such primitives and how to make use of them in various programming styles. Among the techniques that I use to recognize when two concepts complement each other is to emphasize when two things are in a &lt;em&gt;duality&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;A situation of &lt;a href="/hashtags/duality.html"&gt;&lt;span class="hashtag" data-hashtag="duality"&gt;#duality&lt;/span&gt;&lt;/a&gt; is when two concepts cohabit well while appearing in opposition. In a sense, two dual concepts connect and perform some symmetrical dance. I would say that finding that two things are dual is like realizing that it’s not the Earth that rotates around the Moon, nor the Moon rotates around Earth, but in fact both celestial bodies dance and rotate around a same point &lt;a href="https://en.wikipedia.org/wiki/Barycenter#/media/File:Orbit3.gif"&gt;(the barycenter)&lt;/a&gt;. Discovering such rules brings clarity and simplicity to our understanding of a problem. Since a key part of our job in software engineering is to tame complexity, recognizing such simplifications are useful.&lt;/p&gt; &lt;p&gt;The existence of the barycenter of the Earth-Moon system is a consequence of the mathematical formulas we use to model the physical world. It is worth training our sense starting from simple (even simplistic) equations. For instance, let’s take the simplest form of duality: the equality of two values. The two sides of an equality &lt;code&gt;a = b&lt;/code&gt; are in a dual relationship: what happens to &lt;code&gt;a&lt;/code&gt; requires a commensurate compensation on &lt;code&gt;b&lt;/code&gt;. In the real world you rarely encounter some simple rule saying &lt;code&gt;a = b&lt;/code&gt;, more often terms like &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; actually are contraptions. For instance &lt;code&gt;b&lt;/code&gt; is the result of something involving &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;d&lt;/code&gt; and other values. Whatever the particular instance you find, what happens to &lt;code&gt;a&lt;/code&gt; likely has implications on these &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;d&lt;/code&gt; and other values. As systems grow in complexity, such equalities may blossom unexpectedly, and if the formula for the equality is too obscured to be spelled-out, unfathomable dynamics will happen.&lt;/p&gt; &lt;p&gt;Although software is not cosmology, and even if no Great Watchmaker seems needed to enforce laws of equalities (we trust CPU founders to do so), dualities exist in software. Software can be modeled with mathematical concepts from &lt;em&gt;discrete logic&lt;/em&gt; rather than calculus and differential equations. If I had to choose, I would say that the root of all dualities in software are &lt;a href="https://en.wikipedia.org/wiki/De_Morgan%27s_laws"&gt;De Morgan’s laws&lt;/a&gt; (in particular, see the section about extensions to predicate and modal logic). Let’s say that a “negated” value is a &lt;em&gt;consumer&lt;/em&gt; whereas a “positive” value is a &lt;em&gt;producer&lt;/em&gt;. Also, let’s say that a &lt;code&gt;OR&lt;/code&gt; encodes alternatives whereas a &lt;code&gt;AND&lt;/code&gt; encodes co-occurrences. Applying De Morgan’s law &lt;code&gt;NOT (x OR y) = (NOT x) AND (NOT y)&lt;/code&gt; could be read as &lt;strong&gt;to consume either X or Y we need the co-occurrence of a consumer of X and a consumer of Y&lt;/strong&gt;. We will leave such a bureaucratic formalism out of this article but there is not much more to it: a simple logical rule. Instead, I’ll spend time elaborating at a higher-level. In particular I would like to stress how important the producer/consumer duality is in software and how this duality is interlocked with yet another important duality: the alternative/co-occurrence duality.&lt;/p&gt; &lt;h2 id="the-producerconsumer-duality"&gt;The producer/consumer duality&lt;/h2&gt; &lt;p&gt;We do not write code in a vacuum. Even if we write code for no purpose, the programming language has logical rules, running a program happens on a physical machine subject to physical and logical rules of the CPU or those of the virtual machine. Even if we only imagine some code without writing it (e.g., while sketching out an API in our mind), our imaginary simulation of the running code will entail some logical rules. In any case some dualities are likely to arise. In particular, a useful program either consumes some data (e.g., a configuration file), or produces some data (e.g., a PNG image). More often, a programs both consume and produce some data but &lt;strong&gt;the data-consumption-side and data-production-side of a program operate on distinct sets&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;I specifically want to avoid conflating inputs and outputs with produced and consumed data. Although I believe that input and output are in a consumer/producer duality, I also want to encompass side-effects in this duality. A trick in functional programming is to pretend that the external world is a hidden input and hidden output of a pure function. The problem I find with this external-world object is that the external world is both consumed and produced, apparently giving a symmetrical role to the external-world object (for the better or the worst, our programming practice focuses almost only on the program and takes the executing environment as an unprogrammable thing with its own will). I prefer to conceptualize side-effects as entities merely produced by programs. Side-effects then are consumed by their executing environment. In this viewpoint, the program and the executing environment are the two partners performing a tango dance (or the two opponents in a tennis-game if you prefer sport over artistic metaphors). This viewpoint brings the question: what is the dual to a side-effect? It is something that an executing environment provides and that a program consumes (and hence it may destroy it), and I claim that would be pre-conditions. Summarizing, in this viewpoint &lt;strong&gt;a program consumes pre-conditions and produces side-effects&lt;/strong&gt; and could be illustrated as follows:&lt;/p&gt; &lt;p&gt;&lt;img src="gen/images/producer-consumer.dot.png" alt="producer-consumer duality" /&gt;&lt;/p&gt; &lt;p&gt;I spoke about “programs” without precisely describing the kind of program I wanted to describe. Indeed, I believe that such a duality exists at different scales of programming. When zooming in at the individual module, object, or function, we can easily outline pieces of code that produce and consume objects or data-structures. I believe the same rule exists when zooming out a the service level. We just lack proper nouns to disambiguate whether a service mainly produces or consumes other services (indeed, much like the external-world object trick in FP: we conflate the co-occurrence of two distinct phenomenon because when focusing on a sole viewpoint both ends meet). I do not have excellent suggestions to make, but if I were to pick some words today I would say that, a service is being a &lt;strong&gt;producer of functionalities that are consumed as capabilities&lt;/strong&gt; by external-services.&lt;/p&gt; &lt;p&gt;What are the consequences of the dual roles of producers and consumers? Well, there is a point that when you need to modify a producer you need consumers to adapt in a dual way. It’s common to speak about API &lt;em&gt;contracts&lt;/em&gt; to provide a way to match consumers with producers. However I find that speaking at length about the value of contracts falls short. Contracts are shallow, they merely are the tips of the consumers and producers code. We actually can derive much more information than “OK the consumers and producers must agree on a contract”. In particular, we need to be precise about the consequences of changing a producer linked to a consumer. To answer such questions, we need to take a close look at how the producers/consumers duality interacts with the alternative/co-occurrences duality.&lt;/p&gt; &lt;h2 id="the-alternativeco-occurrences-duality"&gt;The alternative/co-occurrences duality&lt;/h2&gt; &lt;p&gt;Alternatives (&lt;a href="/hashtags/alternatives.html"&gt;&lt;span class="hashtag" data-hashtag="alternatives"&gt;#alternatives&lt;/span&gt;&lt;/a&gt;) and co-occurrences are well captured with what are called &lt;em&gt;sum-types&lt;/em&gt; and &lt;em&gt;product-types&lt;/em&gt; in typed-programming languages. Product-types are pervasive in programming, they correspond to your day-to-day data structure that is made of a set of fields. For instance, a user could be represented in some informal pseudo-code &lt;code&gt;type User = { Name x Email x FavoriteColor }&lt;/code&gt;. This notation means that a when you are presented a &lt;code&gt;User&lt;/code&gt; object, you also have the co-occurrence of three separate entities: &lt;code&gt;Name&lt;/code&gt;, &lt;code&gt;Email&lt;/code&gt;, and &lt;code&gt;FavoriteColor&lt;/code&gt;, and you can splice them out at will and independently.&lt;/p&gt; &lt;p&gt;Sum-types, for no clear reason, have less support in the most-established programming languages. To be precise, user-declared sum-types are not really available. A boolean is the simplest example of sum-types, it presents two alternatives &lt;code&gt;type Bool = { False | True }&lt;/code&gt;, that is when you have a &lt;code&gt;Bool&lt;/code&gt;, you may have either a &lt;code&gt;False&lt;/code&gt; or a &lt;code&gt;True&lt;/code&gt; but not both at a same time. You could have a type with three alternatives (e.g., to encode a subscription plan with three tiers &lt;code&gt;type Plan = { Free, Pro, Enterprise }&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;With knowledge of product types and sum types, a compiler or a linter can tell you that you made a mistake (e.g., you forgot to give an &lt;code&gt;Email&lt;/code&gt; to build a &lt;code&gt;User&lt;/code&gt;, or you forgot to provide a template for the &lt;code&gt;Pro&lt;/code&gt; subscription email). Indeed, automated tools have enough information about all possible alternative and all required fields that must co-occur. Since we are discussing dualities and we have discussed about the producer/consumer duality. You may already sense where this post is going: we need to explore what happens to the consumer-side of a produced sum-type or of a produced product type.&lt;/p&gt; &lt;p&gt;Given that a product type is a co-occurrence of independent facts, when you produce a product type, the consumer &lt;em&gt;CAN&lt;/em&gt; have multiple independent data handlers and all can execute. Whereas when you produce a sum type, the consumer &lt;em&gt;MUST&lt;/em&gt; have independent data handlers and only one executes.&lt;/p&gt; &lt;p&gt;Finally, let’s note that a data handlers can also be stored in data types (e.g., with lambdas if the language supports it, or with factory-patterns otherwise). Such data types – containing handlers – themselves can be product and sum types. Putting everything together, we note that &lt;strong&gt;producers of alternatives require a the co-occurrence of consumers&lt;/strong&gt; whereas &lt;strong&gt;producers of co-occurrences require alternatives of consumers&lt;/strong&gt;. That’s it, our two dualities are interlocked.&lt;/p&gt; &lt;p&gt;We can illustrate this duality with pictures by displaying a producer and a consumer being matched together.&lt;/p&gt; &lt;p&gt;On the one hand, we shall illustrate a producer of product-type. Visually we try to convey the code that is written with the yellow boxes with &lt;code&gt;...&lt;/code&gt; ellipsis text in them.&lt;/p&gt; &lt;p&gt;&lt;img src="images/product-producer.png" alt="product-producer" /&gt;&lt;/p&gt; &lt;p&gt;The Producer returns a co-occurrence of three pieces of information (the product type &lt;code&gt;{A,B,C}&lt;/code&gt;). Therefore, the Producer must have code to introduce or carry-over these three independent piece of information. Given that the Producer’s output contains these three pieces of information, the Consumer is free to pick any alternative combining &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, or &lt;code&gt;C&lt;/code&gt;. When Producer and Consumer are &lt;em&gt;decoupled&lt;/em&gt;, the Consumer may not even have code to consume &lt;code&gt;A&lt;/code&gt; or &lt;code&gt;C&lt;/code&gt; and only cares about &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;On the other hand, we also need to illustrate the dual situation where the Producer provides a sum-type.&lt;/p&gt; &lt;p&gt;&lt;img src="images/product-consumer.png" alt="product-consumer" /&gt;&lt;/p&gt; &lt;p&gt;Given that the Producer provides an alternative (again, it may be that there is code for only one possible case), if the Consumer is decoupled from the Producer, then the Consumer must be ready to handle every case.&lt;/p&gt; &lt;p&gt;Much like when we first introduced the producer/consumer duality, we have been pretty indiscriminate about the exact family of producer and consumers.&lt;/p&gt; &lt;p&gt;Indeed, &lt;strong&gt;the alternative/co-occurence duality stands for all scales&lt;/strong&gt;. The only requirement for the duality to exhibit consequences is that a consumer and producer establish some communication (i.e., when we match a consumer with a producer). For instance at the library-scale, the producer could be a library function you call. Your own code would be the consumer of this function. When the library function returns a sum-type (for instance, either an error or a successful result) you should forcefully verify that you have a piece of code to handle either branches. At a service-scale, a web-API with multiple routes or a gRPC service with multiple methods can be framed as a collection of endpoints (i.e., a co-occurrence of handlers) whereas the client-side has the choice to pick any endpoint (i.e., and alternative of endpoints). In summary, the party that can force the dual party to behave in a certain way is the party deciding on the alternative picked in the sum-type side of the producer/consumer interface.&lt;/p&gt; &lt;p&gt;It is worth stressing that the alternative/co-occurrence duality shows up irrespective of the particular role (consumer or producer) of the API-client versus the web-API. Indeed, whether the client of the API is seen as a consumer (e.g., fetching data) or a producer (e.g., pushing data) does not change the fact that at the interface level, the client holds the choice of picking the endpoint. This distinction is important to recognize the proper interface between a producer and a consumer. In real-world situations, software components take both roles in alternation: a web-API may be seen as a producer of endpoints, but to implement an handler for such endpoint, the web-API is a consumer of other services or a consumer of libraries, and so-on and so-forth. Therefore, recognizing the particular interface may be difficult. Indeed, when we say a web-API client is a consumer, the &lt;em&gt;payload&lt;/em&gt; that the web-API produces could either be a product-type (i.e., the servers returns a co-occurrence of data and the client is then free to act starting from this data), but the result could also be a sum-type (i.e., the server returns a particular alternative to force a behaviour on the client – for instance an unauthorized response would force a client to initialize an authentication challenge). When analyzing real-world systems, we realize that communications between systems is a fractal of consumers and producers matched with each others and communicating of product-types and sum-types. Thus, when conceptualizing a system, we need to find the right levels where systems interface with each others and we must study a few nested layers of messages they interact with.&lt;/p&gt; &lt;p&gt;A key reason for studying more than a single level of interface is that it is possible to mechanically flatten nested layers of alternatives/co-occurrences. Such a flattening is useful both as a concept but also as a refactoring tool. The flattening law comes straight out of arithmetic, and is “just” the distributivity property of products over sums.&lt;/p&gt; &lt;p&gt;Formally the distributivity is written as &lt;code&gt;a * (b + c) = (a * b) + (a * c) &lt;/code&gt; In plain English, the two following statements are equivalent:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;you certainly get an &lt;code&gt;a&lt;/code&gt; and alternatively get a &lt;code&gt;b&lt;/code&gt; and a &lt;code&gt;c&lt;/code&gt; &lt;/li&gt; &lt;li&gt;you alternatively get an &lt;code&gt;a&lt;/code&gt; paired with a &lt;code&gt;b&lt;/code&gt; with certainty or &lt;code&gt;a&lt;/code&gt; paired with a &lt;code&gt;c&lt;/code&gt; with certainty &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Much like arithmetic formula we can theorize systems at various scales with similar formulas, and then factorize or develop these formulas. We will expand on this key property in the next section, but let’s first summarize what we’ve seen.&lt;/p&gt; &lt;h3 id="summary"&gt;Summary&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;in a general sense, consumers and producers are in a duality relationship &lt;/li&gt; &lt;li&gt;alternatives (sum-types) and co-occurrences (product-types) also are dual of each other &lt;/li&gt; &lt;li&gt;both dualities interact following some interaction law &lt;ul&gt; &lt;li&gt;producers of sum-types match product-types consumers &lt;/li&gt; &lt;li&gt;producers of product-types match sum-types consumers &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;these properties are invariant of the scale (i.e., it holds at the function, library, service level) &lt;/li&gt; &lt;li&gt;communicating systems involve layered consumer/producers, producers/consumers may alternate from one layer to another &lt;/li&gt; &lt;li&gt;there is a distributivity law to factorize or develop layers of {sum,products}-of-{sum,products}. &lt;/li&gt; &lt;/ul&gt; &lt;h2 id="consequences"&gt;Consequences&lt;/h2&gt; &lt;p&gt;The important consequence of the interactions of product/sum with consumer/producer is that you do not need to be a compiler to foresee whether two pieces of software “connect” well or not. You can foresee errors, plan refactoring, and prepare architecture documents for splitting a monolith into services (or when agglomerating too-thin services into larger ones).&lt;/p&gt; &lt;h3 id="flattening-an-http-response"&gt;flattening an HTTP response&lt;/h3&gt; &lt;p&gt;Say that you are calling a library function that returns an &lt;code&gt;a * (b+c)&lt;/code&gt;, for instance, an HTTP response could be represented as &lt;code&gt;headers ~= a&lt;/code&gt; and &lt;code&gt;body ~= b if the response is valid, c if it's an error message&lt;/code&gt;. Since &lt;code&gt;a * (b + c)&lt;/code&gt; is equivalent to &lt;code&gt;(a * b) + (a * c)&lt;/code&gt;. You can decide to write a handler for “HTTP headers with a body” return value separately from a handler for “HTTP headers with an error”, and collate these two in a single handler for “HTTP headers with either a body or an error”.&lt;/p&gt; &lt;p&gt;If we go further and it happens that &lt;code&gt;b = c + d&lt;/code&gt; (e.g., &lt;code&gt;d&lt;/code&gt; is a decoded JSON object and &lt;code&gt;c&lt;/code&gt; is an error message), we can write down the consequences:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; a * (b + c) = (a * b) + (a * c) [distributivity] = (a * (c + d)) + (a * c) [b=c+d] = (a * c) + (a * d) + (a * c) [distributivity] = (a * c) + (a * c) + (a * d) [commutativity*] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This series of equation means that the HTTP-response handler in our example actually is made of two possibly-independent error-handler pieces of code &lt;code&gt;(a * c)&lt;/code&gt; and a success-handler taking a decoded JSON value &lt;code&gt;(a * d)&lt;/code&gt;. We have not discussed about commutativity here but in general depending on what your operations entails, they may not commute, for the case of decoding JSON values we could safely assume that decoding commutes as one would expect decoding to be deterministic and require no exogenous side-effects.&lt;/p&gt; &lt;p&gt;That’s a lot of information about the code when only looking at a type-description!&lt;/p&gt; &lt;h3 id="refactoring-api-services-with-multiple-endpoints"&gt;refactoring API services with multiple endpoints&lt;/h3&gt; &lt;p&gt;We’ve said earlier than a web-API is a product of handlers. Thus, to say that an API implements &lt;code&gt;a * (b + c)&lt;/code&gt; at a conceptual level means the web-API has two routes (the &lt;code&gt;*&lt;/code&gt; at the first layer) and the payload of the second type is known to be a sum-type (&lt;code&gt;b+c&lt;/code&gt;). If we apply distributivity we get &lt;code&gt;(a * b) + (a* c)&lt;/code&gt; , that is a single endpoint (no &lt;code&gt;*&lt;/code&gt; operand at the first layer) with a payload that is a sum of products.&lt;/p&gt; &lt;p&gt;We can illustrate this operation with the following pseudo-API description of two web-APIs.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;POST /route-one {&amp;quot;payload-a&amp;quot;:&amp;quot;a&amp;quot;} &amp;lt;=&amp;gt; POST /route-combined?branch=case-b {&amp;quot;payload-a&amp;quot;: &amp;quot;a&amp;quot;, &amp;quot;payload-b&amp;quot;: &amp;quot;b&amp;quot;} POST /route-two?branch=case-b {&amp;quot;payload-b&amp;quot;: &amp;quot;b&amp;quot;} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Both situations allow to match similar clients and servers exchanging similar information. However we can see that on the left-side, the client of the API is free to call &lt;code&gt;route-two&lt;/code&gt; even if it does not have a &lt;code&gt;payload-a&lt;/code&gt; to offer, whereas in the right situation, the client of the API must have a &lt;code&gt;payload-a&lt;/code&gt; to call &lt;code&gt;route-combined&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Note that when we say the representations are equivalent, we mean that either &lt;code&gt;a * (b+c)&lt;/code&gt; or &lt;code&gt;(a*b) + (a*c)&lt;/code&gt; are entirely produced and consumed. Commutativity is important in the first case.&lt;/p&gt; &lt;h4 id="some-api-refactoring-where-this-rule-fail"&gt;some API refactoring where this rule fail&lt;/h4&gt; &lt;p&gt;Let’s see an a negative example where you would believe that you can introduce the same transformation. Say you have to pick between using one endpoint or a series of endpoints. Such a situation arises when &lt;strong&gt;in both case you need to encode some branching logic&lt;/strong&gt;: in the URL path or in the payload.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;POST /foo/bar POST /foo {&amp;quot;hello&amp;quot;: &amp;quot;world&amp;quot;} {&amp;quot;hello&amp;quot;: &amp;quot;world&amp;quot;, &amp;quot;branch&amp;quot;: &amp;quot;bar&amp;quot;} &amp;lt;=&amp;gt; POST /foo/baz POST /foo {&amp;quot;hello&amp;quot;: &amp;quot;world&amp;quot;} {&amp;quot;hello&amp;quot;: &amp;quot;world&amp;quot;, &amp;quot;branch&amp;quot;: &amp;quot;baz&amp;quot;} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The key issue here is that we have product types at the API layer, i.e., our only way to factorize this is to use what is known as … you guess it, an exponential type.&lt;/p&gt; &lt;p&gt;&lt;code&gt;a x a x .... [k times] = a ^ k&lt;/code&gt;&lt;/p&gt; &lt;p&gt;And they correspond to functions with an argument. In short, if you had five handlers, you can factorize that into one handler having an extra argument taking five possible values. There is no duality involved here, but it is interesting to note that the product/sum extends to more arithmetic.&lt;/p&gt; &lt;p&gt;Exponentials &lt;code&gt;a ^ k&lt;/code&gt; varies from products &lt;code&gt;a * k&lt;/code&gt; because if we keep this sense of fully-consuming either inputs, you would need to consume multiple &lt;code&gt;a&lt;/code&gt; versus consuming a single &lt;code&gt;a&lt;/code&gt;. Indeed, a client that has the alternative to pick many different A with various handlers, to get the same behaviour we still need the possibility to handle &lt;code&gt;a&lt;/code&gt; differently based on the &lt;code&gt;branch&lt;/code&gt; taken.&lt;/p&gt; &lt;h3 id="monoliths-micro-services-and-it-system-architectures-roll-outs"&gt;monoliths, micro-services, and IT-system architectures roll-outs&lt;/h3&gt; &lt;p&gt;Most companies with a large amount of software need to evolve their code base. Thus, I recommend to recognize three key aspects:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;what is constant about the system? &lt;/li&gt; &lt;li&gt;what is the product/sum nature of the changed system? &lt;/li&gt; &lt;li&gt;are you flattening/nesting the changed system? &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Having these information at hand is like accumulating equations to solve an system of equations until the system is well defined.&lt;/p&gt; &lt;p&gt;For instance, the exercise of splitting a monolith is like going from a large product into some more nested products &lt;code&gt;a * b * c * d&lt;/code&gt; to something more nested &lt;code&gt;(a * b) * (c) * (d)&lt;/code&gt;. The overall number of services is constant and we still have a gigantic product type of endpoints. The latter seems more complicated, so why do we dread monoliths? Well, imagine that now you want to support a new key customer with a new business use-case &lt;code&gt;c = c1 + c2&lt;/code&gt;. Then we can see what happens to monoliths if we want to isolate customers for a reason or another (i.e., if we expose an alternative of sets of simple endpoints rather than exposing a single set of more-complicated endpoints). We distribute the &lt;code&gt;+&lt;/code&gt; and get the following: &lt;code&gt;a * b * (c1 + c2) * d = (a * b * c1 * d) + (a * b * c2 * d)&lt;/code&gt; you need to fork the whole &lt;code&gt;a * b * _ * d&lt;/code&gt; part of the monolith to please the new business. Whereas in the already-factored out situation, we get &lt;code&gt;(a*b) * (c1) * (d) + (a*b) * (c2) * (d)&lt;/code&gt;, that is some set of endpoints are stable and can be re-used more directly.&lt;/p&gt; &lt;h1 id="another-duality"&gt;Another duality&lt;/h1&gt; &lt;p&gt;Before concluding, I would like to pinpoint some related duality that also stems from the producer/consumer viewpoint.&lt;/p&gt; &lt;h2 id="null-and-default-values-are-duals"&gt;null and default-values are duals&lt;/h2&gt; &lt;p&gt;Much has been written about &lt;em&gt;null&lt;/em&gt; being Tony Hoare’s &lt;a href="https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/"&gt;billion-dollar mistake&lt;/a&gt;. Well, my sincere belief if we should regard implicit &lt;em&gt;defaults&lt;/em&gt; (default values) with the same scrutiny. In many languages, &lt;em&gt;null&lt;/em&gt; actually is “THE default value”, but I want to stress that &lt;em&gt;defaults&lt;/em&gt; in itself is a problem.&lt;/p&gt; &lt;p&gt;Why do I believe that &lt;em&gt;null&lt;/em&gt; and &lt;em&gt;defaults&lt;/em&gt; are dual? Well, let’s look at some usages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;null&lt;/em&gt; is here to &lt;em&gt;provide&lt;/em&gt; no-values to some consumer that will &lt;em&gt;consume&lt;/em&gt; one &lt;/li&gt; &lt;li&gt;&lt;code&gt;default&lt;/code&gt; is here to &lt;em&gt;consume&lt;/em&gt; no-value from some producer that should have &lt;em&gt;produced&lt;/em&gt; one &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If we connect to my viewpoint that programs and environment are in a dual dance, we can see that &lt;em&gt;null&lt;/em&gt; affects the program whereas &lt;em&gt;defaults&lt;/em&gt; affect the environment. Indeed, &lt;strong&gt;null shortcuts the program downstream&lt;/strong&gt;, whereas &lt;strong&gt;defaults shortcut the environment upstream&lt;/strong&gt;. Taking the alternate viewpoint of side-effects and pre-conditions, we could say that &lt;strong&gt;null prevents side-effects&lt;/strong&gt; by crashing the system, whereas &lt;strong&gt;defaults prevents wanted pre-conditions&lt;/strong&gt; by not operating on the environment.&lt;/p&gt; &lt;p&gt;An example that makes such a distinction clear is a situation where a networked client needs to perform an authentication challenge. If the authentication challenge occurs and produces a null token, the client will crash. If no authentication-challenge occurs and a default token-value is produced, the client will continue and may leak data or have a failure at a much-later “distance” from where the bug actually is rooted.&lt;/p&gt; &lt;p&gt;I don’t know what is the dual of a billion-dollar mistake, but I hope you will join me in saying that default-values defeat a large number of automated analyses one could hope to make about the correctness of a program.&lt;/p&gt; &lt;h1 id="closing-remarks"&gt;Closing remarks&lt;/h1&gt; &lt;p&gt;This article took me a while to write because the topic I scratched is much deeper than I anticipated. I think that most of the discussion could be re-written entirely as a more formal exercise in mapping the discussions about product/sum-types and API endpoints using &lt;a href="https://en.wikipedia.org/wiki/Linear_logic"&gt;linear logic&lt;/a&gt; rather than my sketchy arithmetic. I definitely care enough about this topic to ask readers to point me works they find (a) introductory enough and (b) related to this discussion.&lt;/p&gt; &lt;p&gt;I reserve myself the right to write about this topic a few more times even if such new articles would have a lot of redundant information. Indeed, I took off bits about negative types, bits about category-theory, and bits about covariance/contra-variance. Overall, there is much to say and we probably longer illustrative examples as well. It feels like there is much, but at a same time these concepts are only just a few.&lt;/p&gt; &lt;/section&gt;&lt;/div&gt;
        </content>
        <link href="https://dicioccio.fr/on-dualities.html" rel="alternate"/>
        <summary type="text">
            Duality is technical jargon for "complementary". Programmers often overlook the role dualities in programming and hence fail to recognize them, even if they are hiding in plain sight. In this article we focus on two important pairs of dual concepts: producers and consumers, sum types and product types. I also spend some time ranting about default values being as bad as null values.
        </summary>
    </entry>
    <entry>
        <id>
            https://dicioccio.fr/how-this-blog-works.html
        </id>
        <title type="text">
            The technology behind this blog
        </title>
        <updated>
            2022-01-30T12:00:00Z
        </updated>
        <author>
            <name>
                Lucas DiCioccio
            </name>
        </author>
        <content type="html">
            &lt;div class="main-article"&gt;&lt;section class="main-section"&gt;&lt;p&gt;I wasn’t &lt;a href="/hashtags/blogging.html"&gt;&lt;span class="hashtag" data-hashtag="blogging"&gt;#blogging&lt;/span&gt;&lt;/a&gt; much. I used to prefer giving meetup &lt;a href="/talks.html"&gt;talks&lt;/a&gt;, then the pandemic came and I wanted to start blogging a bit. I wrote nothing, mostly due to the lack of blogging platform I liked. This year, one resolution I took is to remediate this situation and start writing some technical content. After past and more recent attempts at using a SAAS blogging platform, hosting a Wordpress, or generating a Jekyll site, or hand-written HTML files; I always got frustrated.&lt;/p&gt; &lt;p&gt;I always felt some friction between writing content and laying-out content. Writing requires some uninterrupted stream of thought, whereas formatting HTML require focus and repeated trial-and-errors cycles. Writing the text in one document and then formatting the HTML aside in another tool typically is not sufficient because any change requires modifications in multiple places.&lt;/p&gt; &lt;p&gt;Without much surprise, I ended up writing my own engine. This article explains what I really want of a blog-engine and how I’ve implemented it. Little code is shown and ideas are applicable whatever tech-stack you pick.&lt;/p&gt; &lt;h1 id="requirements"&gt;Requirements&lt;/h1&gt; &lt;p&gt;Let’s make a checklist&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;input type="checkbox" disabled&gt; static-site first, APIs second &lt;/li&gt; &lt;li&gt;&lt;input type="checkbox" disabled&gt; live preview with auto reload &lt;/li&gt; &lt;li&gt;&lt;input type="checkbox" disabled&gt; markdown for the meaty content, functional layouts &lt;/li&gt; &lt;li&gt;&lt;input type="checkbox" disabled&gt; customizable CSS, JS per article &lt;/li&gt; &lt;li&gt;&lt;input type="checkbox" disabled&gt; metadata for layout and stats &lt;/li&gt; &lt;/ul&gt; &lt;h3 id="static-site-first-serving-second"&gt;static-site first, serving second&lt;/h3&gt; &lt;p&gt;Hosting a static site is much simpler. GitHub does it for free. At this point I cannot justify maintaining API endpoints for posting comments, nor a database to store them. I still would like to be able to fluidly move to something beefier with a web server. When such a move arises, I would not want to have to port all the meaty content. That is, if I occasionally need an API call, I can still imagine having a static-site first, with only a meager amount of web-serving.&lt;/p&gt; &lt;p&gt;A nice side-effect is that &lt;code&gt;git&lt;/code&gt; is a natural database of content, and git-based flows could serve in multi-authors situations (or for instance to let people use GitHub to add invited-content/comments on the blog).&lt;/p&gt; &lt;h3 id="developer-mode-with-live-preview"&gt;developer mode with live-preview&lt;/h3&gt; &lt;p&gt;I like quick feedback loops. The fastest feedback loop I can think of is a WYSIWYG editor. However my experience with WYSIWYG is not great. To make WYSIWYG works, tools require pretty stringent feature constraints. For instance it is hard to be consistent across pages due to the free-hand nature of WYSIWYG tools. WYSIWYG tools work with their internal and opaque data structures, which then hinder composition with other software and may have challenging upgrade paths.&lt;/p&gt; &lt;p&gt;From experience with LaTeX and markdown in GitHub/GitLab documents, I think a fast-preview is good enough. A Live-preview like in HTML-IDE is almost as good as the immediacy of WYSIWYG. Given that I am writing HTML content, I could use a JS script to automatically reload after changes like some JS applications frameworks (e.g., NextJS) offer.&lt;/p&gt; &lt;h3 id="markdown-for-the-meaty-content-functional-layouts"&gt;markdown for the &lt;em&gt;meaty&lt;/em&gt; content, functional layouts&lt;/h3&gt; &lt;p&gt;To make a blog page you need two broad set of HTML information, the meaty content and the layout parts. The meaty content is the large amount of words and paragraphs and images that make the core of the site. This is what readers are interested in. The layout is what readers (and robots) need to navigate and discover the content. The layout adds some wrapping and normalization of headers, footers etc.&lt;/p&gt; &lt;p&gt;To write meaty-content, you typically want a language with little line-noise than then renders to HTML chunks. Platforms have a variety of syntax for this. For instance, Wikipedia has its own format with specific features to recognize links between articles etc. Beside supporting a ‘flow of consciousness’ approach, these formats are good because we can easily re-use existing tooling such as the &lt;code&gt;aspell&lt;/code&gt; spellchecker, &lt;code&gt;grep&lt;/code&gt; to locate some keywords without too much false-positive. For my own blog I settled on &lt;a href="https://commonmark.org/"&gt;Commonmark&lt;/a&gt; which is roughly &lt;em&gt;enhanced-markdown-with-a-proper-spec&lt;/em&gt;. Commonmark has been invented by one author of Pandoc, which gives a lot of credit to the initiative.&lt;/p&gt; &lt;p&gt;In tension with the “meaty content” is the “layout”. We need to wrap out meaty content with repetitive information but also with a fair amount of article-specific dynamic information (e.g., the publication date should always be at the same position, a list of keywords should be present when keywords are present). I need some automated templating to achieve a proper layout, some templating languages exist like &lt;a href="https://mustache.github.io/"&gt;Mustache&lt;/a&gt;, &lt;a href="https://haml.info/"&gt;Haml&lt;/a&gt;, &lt;a href="https://pkg.go.dev/text/template"&gt;GoTemplate&lt;/a&gt;, but I always felt the overhead of learning these specific syntaxes and using these outweighs their benefit. Let me elaborate a bit: these templating languages are constrained to avoid doing things like starting a web-server while rendering some HTML. They support constructs like iterations into structures for repeated information (e.g., for each tag add a &lt;code&gt;&amp;lt;li&amp;gt;{{tag.name}}&amp;lt;/li&amp;gt;&lt;/code&gt; content). This is all good, however for any non-trivial layout, you end up preparing a very specific data structure with all the right computations (e.g., sorting, numbering things). In the end, you need to morally prepare your template twice: first in the rendering to HTML in the template language itself, a second time in the data structure you pass to the template engine. Maintenance is complicated, and you lose a lot of type checking benefits at the boundary between your main language and your templating language. In short, you gained little at extra cost.&lt;/p&gt; &lt;p&gt;In my opinion, templating and layout are solved by restricting oneselves to pure-functions from some dataset to an HTML structure &lt;code&gt;DataSet -&amp;gt; HTML&lt;/code&gt;. Hence, functional programming is &lt;strong&gt;the right tool for the job&lt;/strong&gt;. I happen to know Haskell well, the author of Commonmark wrote a couple of libraries in Haskell &lt;span class="emoji" data-emoji="arrow_right"&gt;➡️&lt;/span&gt; overall I have no reasons to shy away and pick something different.&lt;/p&gt; &lt;h3 id="customizable-metadata-css-js-per-article"&gt;customizable metadata, CSS, JS per article&lt;/h3&gt; &lt;p&gt;I have ideas for some articles that would benefit from having special CSS or special JS scripts (e.g., to add some interactivity). Ideally, I want the ability to insert assets on a per-page basis. Since there are different reasons for inserting a specific asset (e.g., the layout is different for a generated article listing than for a normal article), customization could be written at the Haskell side or in the meaty content but in most cases we should configure that from the meaty content. Ideally, I would type multiple sections in a single file to avoid spreading what is a single article into many files with a proper directory structure (I don’t enjoy structuring directories until I feel enough pain to do so). An example of files with sections are &lt;a href="https://en.wikipedia.org/wiki/MIME#Multipart_messages"&gt;multipart-emails&lt;/a&gt;. And your email client can totally make sense of images, HTML parts, text parts from a condensed text file. Let’s take inspiration on this.&lt;/p&gt; &lt;h2 id="synthesis-of-requirements"&gt;Synthesis of requirements&lt;/h2&gt; &lt;p&gt;The thing I want is some Haskell-variant that (a) interprets markdown-like files for the &lt;em&gt;meaty content&lt;/em&gt; then passes that into (b) some rendering function. These files could (c) be augmented with extra data and extra CSS/JS. The tool I want would have a generate-static-site and a serve-on-the-fly-files to accommodate the ambivalent ‘static but also live but also with an API if I want one day’ aspects.&lt;/p&gt; &lt;p&gt;I don’t really want to invest time in learning something that will be irritating in one of these dimensions. Established tools may be too rigid to accommodate some of my quirks. The closest tool I found likely is &lt;a href="https://jaspervdj.be/hakyll/"&gt;Hakyll&lt;/a&gt;, a Haskell static-site generation library. It supports some form of metadata per-article for customizing the article (e.g., picking a certain layout) but I really want to insert multiple sections.&lt;/p&gt; &lt;p&gt;Thus, overall, I got a pretext to &lt;strong&gt;invent my own&lt;/strong&gt; &lt;span class="emoji" data-emoji="nerd_face"&gt;🤓&lt;/span&gt; .&lt;/p&gt; &lt;h1 id="implementation"&gt;Implementation&lt;/h1&gt; &lt;p&gt;Let’s first say that the implementation I present here does not represent the whole iterations. I first started with a simple file-to-file generator taking exactly one &lt;code&gt;.cmark&lt;/code&gt; file with multiple sections and turning that into &lt;code&gt;.html + .css&lt;/code&gt; . Proper layouts and live-reloads came later, the whole blog has been a single Haskell file until long (i.e., when compilation time where too long while changing only the layout).&lt;/p&gt; &lt;p&gt;This section does not speak about Haskell but rather focuses on the general architecture. Thus when I say “a function” you can imagine it’s “a monad” if you feel compelled to entertain an annoying cliché about Haskellers detached from reality.&lt;/p&gt; &lt;h2 id="main-architectural-blocks"&gt;Main Architectural Blocks&lt;/h2&gt; &lt;p&gt;The following picture sketches roughly the blog engine pipeline.&lt;/p&gt; &lt;p&gt;&lt;img src="/gen/images/blog-phases.dot.png" alt="pipeline" /&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;compile&lt;/strong&gt; &lt;code&gt;ghc&lt;/code&gt; turns Haskell code into a &lt;code&gt;binary&lt;/code&gt; that contains the blog layout and advanced rules &lt;/li&gt; &lt;li&gt;&lt;strong&gt;read&lt;/strong&gt; collects all input files, possibly other sources &lt;/li&gt; &lt;li&gt;&lt;strong&gt;assemble&lt;/strong&gt; builds an understanding of everything that needs to be generated, copied etc. &lt;/li&gt; &lt;li&gt;&lt;strong&gt;produce&lt;/strong&gt; writes all the needed files to the right location &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;So overall it is pretty simple and nothing is ground-breaking. Assuming the compile step is already done you have a binary. The binary will have a fixed layout that can generate a blog for new content. To illustrate, adding a &lt;em&gt;new article&lt;/em&gt; is done by adding a new &lt;code&gt;.cmark&lt;/code&gt; file but &lt;strong&gt;requires no recompilation&lt;/strong&gt;. But &lt;em&gt;changing the HTML&lt;/em&gt; structure to display the social links &lt;strong&gt;requires a code-change and a recompilation&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;To motivate the next sections it is worth detailing the assembly-part of the blog engine. Let’s focus on &lt;code&gt;read -&amp;gt; assemble -&amp;gt; produce&lt;/code&gt; steps.&lt;/p&gt; &lt;h3 id="detailed-assembly-pipeline"&gt;detailed assembly pipeline&lt;/h3&gt; &lt;p&gt;A more detailed conceptual pipeline of the three last steps is as follows. In the following graph arrows represent the data flow (i.e., starting from inputs data representations progress towards the output files).&lt;/p&gt; &lt;p&gt;&lt;img src="/gen/images/blog-engine.dot.png" alt="pipeline" /&gt;&lt;/p&gt; &lt;p&gt;At the top you get input files such as CSS or Commonmark files. We could easily add external inputs as well. All these sources get stuffed into an object named &lt;code&gt;Site&lt;/code&gt; which sort of contains the whole knowledge about inputs for a Site.&lt;/p&gt; &lt;p&gt;An &lt;code&gt;assemble&lt;/code&gt; function then takes the &lt;code&gt;Site&lt;/code&gt; and turns that into &lt;code&gt;Targets&lt;/code&gt; objects. The Targets themselves are not yet concrete files. Rather, they are annotated recipes about how to produce a single output. The recipe itself is named a &lt;code&gt;Production Rule&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;Production Rules&lt;/code&gt; then can be executed on demand to either generate static files or being generated on the fly by a web-server (if the web-server is written in Haskell). We are lucky enough to have very good web-servers and web-API libraries in Haskell which allows to compose such an hybrid system – this hybrid system is handy for the developer-mode.&lt;/p&gt; &lt;p&gt;A key aspect of the pipeline (highlighted in the picture) is that the &lt;code&gt;assemble&lt;/code&gt; function actually is a bit more complicated than a mere mapping from JS, Markdown etc. There are two complications:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Extra-Targets can be computed from main targets, for instance each topic gets a listing page. These rules mainly are written in Haskell: the &lt;code&gt;index.cmark&lt;/code&gt; also needs the list of all &lt;code&gt;Article&lt;/code&gt; targets to generate extra content on top of some text written in Commonmark; for each &lt;code&gt;tag&lt;/code&gt; we create an index Target page and they all use the same &lt;code&gt;tags.cmark&lt;/code&gt; instructions &lt;/li&gt; &lt;li&gt;&lt;code&gt;Articles&lt;/code&gt; are written in Commonmark however the blog engine expects a special format that contains &lt;code&gt;Sections&lt;/code&gt;, these Sections contain the meaty content but also metadata information in JSON and commands that could lead to generating more files &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Overall, I need to use an ad-hoc mix of Haskell and Commonmark to generate pages and their templates. This mix is means there sometimes is two ways to do a thing (e.g., should I add some default CSS file in the layout or via includes in the CSS-section of individual articles so that I can override it entirely?) with no clear immediate tradeoff.&lt;/p&gt; &lt;h3 id="sample-output"&gt;sample output&lt;/h3&gt; &lt;p&gt;When the binary executes you get an uninteresting log of what occurs. This log can help understand what happens.&lt;/p&gt; &lt;div id="sample-output-txt"&gt; &lt;pre&gt;&lt;code class="language-text"&gt;found site-src/talks.md found site-src/how-this-blog-works.md found site-src/snake-cube.md found site-src/alphabets.md found site-src/tags.md found site-src/santa-wrap.md found site-src/about-me.md found site-src/index.md generating out/gen/out/index.md__gen-date.txt executing `date` with args [] generating out/gen/out/index.md__gen-git-head-sha.txt executing `git` with args [&amp;quot;rev-parse&amp;quot;,&amp;quot;HEAD&amp;quot;] assembling out/talks.html assembling out/how-this-blog-works.html assembling out/snake-cube.html assembling out/alphabets.html assembling out/santa-wrap.html assembling out/about-me.html assembling out/index.html copying out/images/snake-cube-folded.jpeg copying out/images/snake-cube-l-shape.png copying out/images/snake-cube-mzn-003.png copying out/images/snake-cube-coords.png copying out/images/snake-cube-mzn-001.png copying out/images/sword.png copying out/images/layout-restricted.png copying out/images/geost-doc.png copying out/images/parts.png copying out/images/background.png copying out/images/snake-cube-mzn-002.png copying out/images/layout-robot-200x240.png copying out/images/deps.png copying out/images/layout-190x150.png copying out/images/layout-190x160.png copying out/images/haddock-jp.png copying out/images/snake-cube-unfolded.jpeg copying out/images/linear-layout.png generating out/gen/images/blog-phases.dot.png executing `dot` with args [&amp;quot;-Tpng&amp;quot;,&amp;quot;-o&amp;quot;,&amp;quot;/dev/stdout&amp;quot;,&amp;quot;site-src/blog-phases.dot&amp;quot;] generating out/gen/images/blog-engine.dot.png executing `dot` with args [&amp;quot;-Tpng&amp;quot;,&amp;quot;-o&amp;quot;,&amp;quot;/dev/stdout&amp;quot;,&amp;quot;site-src/blog-engine.dot&amp;quot;] copying out/css/index-wide.css copying out/css/index-narrow.css copying out/css/main.css copying out/js/autoreload.js assembling out/topics/about-me.html assembling out/topics/constraint-programming.html assembling out/topics/formal-methods.html assembling out/topics/fun.html assembling out/topics/haskell.html assembling out/topics/minizinc.html assembling out/topics/optimization.html assembling out/topics/sre.html assembling out/topics/web.html generating out/json/paths.json generating out/json/filecounts.json &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(this excerpt is out of date but not you get the boring feeling)&lt;/p&gt; &lt;/div&gt; &lt;h2 id="section-based-file-format"&gt;Section-based file format&lt;/h2&gt; &lt;p&gt;An input file for an Article is suffixed &lt;code&gt;.cmark&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The content of a single file with multiple sections is a file like the following example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;=base:build-info.json {&amp;quot;layout&amp;quot;:&amp;quot;article&amp;quot; } =base:preamble.json {&amp;quot;author&amp;quot;: &amp;quot;Lucas DiCioccio&amp;quot; ,&amp;quot;date&amp;quot;: &amp;quot;2022-02-01T12:00:00Z&amp;quot; ,&amp;quot;title&amp;quot;: &amp;quot;An article about Haskell&amp;quot; } =base:topic.json {&amp;quot;topics&amp;quot;:[&amp;quot;haskell&amp;quot;, &amp;quot;some-tag&amp;quot;] ,&amp;quot;keywords&amp;quot;:[&amp;quot;some keyword&amp;quot;] } =base:social.json {&amp;quot;twitter&amp;quot;: &amp;quot;me&amp;quot; ,&amp;quot;linkedin&amp;quot;: &amp;quot;myself&amp;quot; ,&amp;quot;github&amp;quot;: &amp;quot;again-me&amp;quot; } =base:summary.cmark Some summary. =base:main-content.cmark # this is an h1 title ## this is an h2 title lorem ipsum ... =base:main-css.css @import &amp;quot;/css/main.css&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Each section is a textual block starting with a special delimiter like &lt;code&gt;=base:build-info.json&lt;/code&gt;. The layout code actually interprets these sections and look for various information. For instance, the &lt;code&gt;=base:topic.json&lt;/code&gt; contains information to add some topic-index and &lt;code&gt;meta&lt;/code&gt; tags. The &lt;code&gt;=base:main-css.css&lt;/code&gt; section allows to write some CSS that will be inlined in the HTML (conversely, &lt;code&gt;.css&lt;/code&gt; files found in the source directory will be copied around).&lt;/p&gt; &lt;p&gt;These sections could all be collapsed in a single section however I find it convenient to have one small datatype per logical ‘metadata’ piece.&lt;/p&gt; &lt;h2 id="dev-mode-and-auto-reload"&gt;Dev-mode and auto-reload&lt;/h2&gt; &lt;p&gt;The dev-server API itself is written with my &lt;a href="https://github.com/lucasdicioccio/prodapi"&gt;prodapi&lt;/a&gt; API library, which curates some good Haskell libraries for building APIs. There is enough to help running background tasks in the process (e.g., to watch for file-changes), and also to expose other dev-mode-only endpoints.&lt;/p&gt; &lt;p&gt;Examples of dev-mode-only endpoints are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;a listing of all targets (which is useful when I lose track of what targets exist) &lt;/li&gt; &lt;li&gt;an endpoint I can call to rebuild the static-file outputs from the dev-server directly (rather than running the binary with different parameters) &lt;/li&gt; &lt;li&gt;build-time statistics &lt;/li&gt; &lt;li&gt;autoreload-helpers (see the dedicated section below) &lt;/li&gt; &lt;/ul&gt; &lt;h3 id="autoreload"&gt;autoreload&lt;/h3&gt; &lt;p&gt;I have a poor-man’s &lt;code&gt;autoreload.js&lt;/code&gt; script (source here &lt;a href="/js/autoreload.js"&gt;source of auto-reload script&lt;/a&gt;). That perform long-polling to a API route &lt;code&gt;/dev/watch&lt;/code&gt; that only the dev-webserver knows about (i.e., there won’t be a Target to generate for this URL path). The &lt;code&gt;autoreload.js&lt;/code&gt; script performs a full-page reload, which is acceptable as most of the articles I will ever write will mostly be stateless texts but.&lt;/p&gt; &lt;p&gt;The current implementation works using the amazing Software Transactional Memory (STM) support in Haskell and supports live-reloading mutliple pages simultaneously from different clients connected to a same server (not like I really use this feature but it does not incur much more work). Implementation of the live-reload is illustrated as follows:&lt;/p&gt; &lt;p&gt;&lt;img src="/gen/images/autoreload-watches.dot.png" alt="autoreload" /&gt;&lt;/p&gt; &lt;p&gt;The server API route mediates a rendez-vous between:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;code&gt;Web Browser&lt;/code&gt; who waits for an answer to the API call &lt;/li&gt; &lt;li&gt;&lt;code&gt;Filesystem&lt;/code&gt; changes that are propagated via inotify &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Overall, from a high-level perspective the live-reload follows these four simple steps:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Step-0. after loading the &lt;code&gt;.js&lt;/code&gt; a browser starts a watch over the HTTP request API handler &lt;/li&gt; &lt;li&gt;Step-1. inotify notifies the file-system change &lt;/li&gt; &lt;li&gt;Step-2. the watch terminates &lt;/li&gt; &lt;li&gt;Step-3. the HTTP request finishes, the browser reloads (which will return to Step-0) &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Three threads co-exist in the server:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;the &lt;code&gt;inotify&lt;/code&gt; callbacks loads targets then propagates them in a &lt;em&gt;Site&lt;/em&gt; (using a &lt;code&gt;TMVar Site&lt;/code&gt;), this thread is like if an event-stream of updated Sites was available but we only hold-on to the latest value &lt;/li&gt; &lt;li&gt;the &lt;code&gt;api&lt;/code&gt; registers a &lt;em&gt;Watch&lt;/em&gt; (using one &lt;code&gt;TMVar ()&lt;/code&gt; per HTTP-request) and inserts it in a list of pending watchers &lt;em&gt;[Watch]&lt;/em&gt; , then waits for the Watch to end &lt;/li&gt; &lt;li&gt;the server &lt;code&gt;background&lt;/code&gt; waits for the filesystem flag changes, clears the flag, then fans-out the signal to waiting HTTP-clients, all of this is atomic outside the STM area (all the changeds are annotated &lt;code&gt;flush&lt;/code&gt; in orange on the picture) &lt;/li&gt; &lt;/ul&gt; &lt;h1 id="experience-report"&gt;Experience report&lt;/h1&gt; &lt;p&gt;It has been fun to write some get-stuff-done Haskell. I sincerely believe this blog engine does not have to shy away in face of other tools. I will surely try to extract the library code as a standalone engine at some point, but for now my repository mixes library, specific layout and rules for my own blog, and content.&lt;/p&gt; &lt;p&gt;Let me explain a few things that I find rather pleasant.&lt;/p&gt; &lt;h2 id="sections-and-file-generators"&gt;Sections and file generators&lt;/h2&gt; &lt;p&gt;Some interesting Sections and ProductionRules:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;dotfile conversion: turn a &lt;code&gt;.dot&lt;/code&gt; file into a &lt;code&gt;.png&lt;/code&gt; with &lt;a href="https://graphviz.org/"&gt;GraphViz&lt;/a&gt;; the live-reload in the output web-page without leaving &lt;code&gt;vim&lt;/code&gt; makes it a breeze (see video below) &lt;/li&gt; &lt;li&gt;section command-gen: generates a file from a UNIX command (e.g., to get a special file with the git-sha or build timestamp) &lt;/li&gt; &lt;li&gt;section summary: short Commonmark content that appear in article listings (it also gets stripped down to text to add a meta tag) &lt;/li&gt; &lt;li&gt;section taken-off: stuff that is in the source but will be ignored, useful for draft sections &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The following video gives an idea of how the live-reload of GraphViz-generated images work:&lt;/p&gt; &lt;video width="640" height="480" controls&gt; &lt;source src="/videos/demo-blog.webm.mp4" type="video/mp4"&gt; &lt;source src="/videos/demo-blog.webm" type="video/webm"&gt; &lt;/video&gt; &lt;p&gt;I find this live-reload good enough to now run my blog-engine when I need to quickly edit such a graph for work.&lt;/p&gt; &lt;h2 id="commonmark-is-great"&gt;Commonmark is great&lt;/h2&gt; &lt;p&gt;The Commonmark package &lt;a href="https://github.com/jgm/commonmark-hs/tree/master/commonmark-extensions"&gt;supports extensions&lt;/a&gt;. For instance, I have enabled the emoji syntaxt that turns &lt;code&gt;:smiley:&lt;/code&gt; into &lt;span class="emoji" data-emoji="smiley"&gt;😃&lt;/span&gt;. I also enabled support for directly adding HTML tags (including JS) or annotating sections of code with HTML attributes if the rendering is not sufficient. Another use case is when you want to drop down to HTML or if you need small-scripting capabilities.&lt;/p&gt; &lt;p&gt;With HTML-tagging and JS inclusion, the following code:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;::: {.example} press to get an alert &amp;lt;button class=&amp;quot;example-button&amp;quot; onClick=&amp;quot;alert('hi from commonmark')&amp;quot;&amp;gt;press me&amp;lt;/button&amp;gt; ::: &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;… gives the following rendering (with some CSS style defined in the CSS-section).&lt;/p&gt; &lt;div class="example"&gt; &lt;p&gt;&lt;strong&gt;press to get an alert&lt;/strong&gt; &lt;button class="example-button" onClick="alert('hi from commonmark')"&gt;press me&lt;/button&gt;&lt;/p&gt; &lt;/div&gt; &lt;h2 id="you-can-get-creative"&gt;You can get creative&lt;/h2&gt; &lt;p&gt;Direct-embedding of JavaScript allows me to write JavaScript as page-enhancement snippets (e.g., adding a ‘mail-to’ tag for each talk in the &lt;a href="/talks.html"&gt;Talks&lt;/a&gt; page). What excites me the most is that I can also build some full-blown visualizations (e.g., the graph-view on the &lt;a href="/index.html"&gt;home page&lt;/a&gt;). The Haskell-side of the blog-engine allows me to implement pretty much arbitrary logic to prepare some JSONs objects as special targets. Such objects typically are article-specific or site-wide summaries. I can then treat these targets as API endpoints that have fixed content once the site is entirely-produced but where the data is dynamically-recomputed while in developer mode.&lt;/p&gt; &lt;h3 id="site-wide-statistics"&gt;site-wide statistics&lt;/h3&gt; &lt;p&gt;An example of this JavaScript usage below shows you can embed JavaScript for visualizations (example with &lt;a href="https://vega.github.io/vega-lite/usage/embed.html"&gt;Vega-Lite&lt;/a&gt;). Further, the visualization loads a special file &lt;a href="/json/filecounts.json"&gt;json-file-counts&lt;/a&gt; that has been generated as a special Target part of the layout. However, a generator section could also create a similar target.&lt;/p&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vega@5.21.0"&gt;&lt;/script&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vega-lite@5.2.0"&gt;&lt;/script&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vega-embed@6.20.2"&gt;&lt;/script&gt; &lt;div id="vis"&gt; &lt;/div&gt; &lt;script type="text/javascript"&gt; var yourVlSpec = { $schema: 'https://vega.github.io/schema/vega-lite/v5.json', description: 'A simple bar chart with embedded data.', data: { url: "/json/filecounts.json" }, mark: 'bar', encoding: { x: {field: 'srctype', type: 'ordinal'}, y: {field: 'count', type: 'quantitative'} } }; vegaEmbed('#vis', yourVlSpec); &lt;/script&gt; &lt;h3 id="article-shape-statistics"&gt;article-shape statistics&lt;/h3&gt; &lt;p&gt;I typically try to balance-out my articles. While writing LaTex, it’s easy to see the page/column count per page. In HTML we do not really have an immediate equivalent.&lt;/p&gt; &lt;p&gt;A good example of per-article statistics is a histogram made with &lt;a href="https://echarts.apache.org"&gt;Apache ECharts&lt;/a&gt; that I produce and display while in developer-mode to get a visual glimpse of how the article is shaped.&lt;/p&gt; &lt;script src="js/echarts.min.js"&gt;&lt;/script&gt; &lt;script src="js/jquery-3.6.0.min.js"&gt;&lt;/script&gt; &lt;script src="js/echart-histogram.js"&gt;&lt;/script&gt; &lt;div id="histogram"&gt; &lt;/div&gt; &lt;p&gt;On the X-axis you get an index of text blocks in the Commonmark file. Whereas the Y-axis is the cumulative number of words so far. This way I can visualize what is the shape of the article and detect highly-imbalanced paragraphs. This histogram is “work in progress” and I tend to adapt it when I feel like it (I would like to also have markers for images/links). This visualization is automatically-inserted in the “developer mode” layout. However, given that the JSON object target with the article stats is &lt;a href="/json/how-this-blog-works.cmark.json"&gt;a generated target&lt;/a&gt;, I can show you in this article by manually inserting the &lt;a href="/js/echart-histogram.js"&gt;JavaScript&lt;/a&gt;. The JavaScript code knows the URL to the special target for the current article with statistics by looking up a custom &lt;code&gt;&amp;lt;meta&amp;gt;&lt;/code&gt; tag, so that the JavaScript include does not require tweaking or per-page configuration. Longer term, I may decorate every article with such a navigation help.&lt;/p&gt; &lt;h2 id="future-ideas"&gt;Future ideas&lt;/h2&gt; &lt;p&gt;Besides open-sourcing the engine (which means tracking hardcoded things or personal-layouts, plus maintaining an external project). There is much I would like to implement. Unfortunately, these ideas have an activation function a bit higher than I have energy these days. More bluntly, I’d rather focus on writing more content rather than working on the blog engine itself.&lt;/p&gt; &lt;p&gt;Regarding &lt;em&gt;templating&lt;/em&gt;. I still would like some interpreted templating (e.g., Mustache) for some very specific cases such as data tables, with data generated from another section. The reason is that to add a new article I should write code only for the article rather than splitting haskell and Commonmark around (exceptions are special pages like &lt;code&gt;tags.md&lt;/code&gt; and &lt;code&gt;index.md&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;This will require some extra wiring in the Target-assembly part and some difficult decision as to what is really-static and what is in-fact dynamic. My main inspiration are &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; notebooks.&lt;/p&gt; &lt;p&gt;Regarding new &lt;em&gt;sections&lt;/em&gt;, &lt;em&gt;targets&lt;/em&gt;, or &lt;em&gt;layouts&lt;/em&gt;. I would like to allow to have scripting-language sections (for now I only have direct shell commands). For instance to generate a picture using &lt;code&gt;R&lt;/code&gt; or &lt;code&gt;Python&lt;/code&gt;. It would be nice as well to inline the dot-source of GraphViz pictures directly in the &lt;code&gt;.cmark&lt;/code&gt; file. RSS targets also are on my wishlist, however I do not use a lot of RSS myself. I also would like to have some article-type layouts for photo albums and snippet-like entries (e.g. to improve on the &lt;a href="/tips.html"&gt;Tips page&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;Regarding &lt;em&gt;dependency-graphs&lt;/em&gt;. I would like to have a section where required URLs can be declared. Doing so will enable more interesting build sequences.&lt;/p&gt; &lt;p&gt;As a &lt;em&gt;fluid static to web-app engine&lt;/em&gt;, I think this blog-engine is a good starting-point for mixed website where some pages or endpoint are dynamic API calls. I already have a “serve mode” for the day where I feel compelled to move out of GitHub pages. The “serve-mode” for now is just the “dev mode” but without the special-routes and special-layouts but it would need some extra configurations and simple caching strategies to reduce security-risk vectors (e.g., to prevent arbitrary-commands generators and costly targets to be run on demand).&lt;/p&gt; &lt;p&gt;Some inspiration for future work can also be found in the &lt;a href="/readings.html#static-and-personal-site-technology"&gt;Readings&lt;/a&gt; page (section “Static and personal site technology).&lt;/p&gt; &lt;/section&gt;&lt;/div&gt;
        </content>
        <link href="https://dicioccio.fr/how-this-blog-works.html" rel="alternate"/>
        <summary type="text">
            The overengineering behind this blog. Or is it not over-engineered?
        </summary>
    </entry>
</feed>
